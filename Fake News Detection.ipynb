{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30dbb1ea-b37c-4772-80ba-a4cd0d7a2143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\new folder\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9ceee7-8b81-4f01-a7fa-41db5f1e506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765d671c-696b-42f1-8148-f27fd6aecc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\New folder\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d5cfed7-d6cb-414a-ac39-02cc6d68b881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\new folder\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca2d0b5-5f6a-4120-8969-35afd599d3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported successfully!\n",
      "Scikit-Learn Version: 1.6.1\n",
      "NLTK Version: 3.8.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "import flask\n",
    "\n",
    "print(\"All packages imported successfully!\")\n",
    "print(\"Scikit-Learn Version:\", sklearn.__version__)\n",
    "print(\"NLTK Version:\", nltk.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566fbdb8-6838-4102-a407-56a7a8cb8624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\new folder\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in e:\\new folder\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in e:\\new folder\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in e:\\new folder\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: flask in e:\\new folder\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\new folder\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\new folder\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\new folder\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in e:\\new folder\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\new folder\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in e:\\new folder\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in e:\\new folder\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in e:\\new folder\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in e:\\new folder\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in e:\\new folder\\lib\\site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\new folder\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\new folder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn nltk flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac61b481-bcfa-4d6f-bbec-e477781fc230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\new folder\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in e:\\new folder\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in e:\\new folder\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in e:\\new folder\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: flask in e:\\new folder\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\new folder\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\new folder\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\new folder\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in e:\\new folder\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\new folder\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in e:\\new folder\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in e:\\new folder\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in e:\\new folder\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in e:\\new folder\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in e:\\new folder\\lib\\site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\new folder\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\new folder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn nltk flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "850c7ec4-0d0c-452e-9415-b21d1de052b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8949d6c4-c4a3-4691-bb30-c02ec8789602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset prepared successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load only 10,000 rows to reduce processing time\n",
    "fake_data = pd.read_csv(\"Fake.csv\", nrows=500)\n",
    "true_data = pd.read_csv(\"True.csv\", nrows=500)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "\n",
    "# Add labels: 1 for True, 0 for Fake\n",
    "fake_data[\"label\"] = 0\n",
    "true_data[\"label\"] = 1\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([fake_data, true_data])\n",
    "\n",
    "# Shuffle the dataset to mix fake and real news\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset prepared successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdcf9dda-9a2e-4f75-80f2-3833c4a30297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Despite the fact that Donald Trump and his fan...   \n",
      "1  WASHINGTON (Reuters) - The top Democrat on the...   \n",
      "2  James Clapper, the Director of National Intell...   \n",
      "3  (Reuters) - U.S. President Donald Trump has ag...   \n",
      "4  You may not be familiar with the name  Unileve...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  despite fact donald trump fanbase try convince...  \n",
      "1  washington reuters top democrat senate judicia...  \n",
      "2  james clapper director national intelligence p...  \n",
      "3  reuters u president donald trump agreed meet r...  \n",
      "4  may familiar name unilever good chance product...  \n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text in brackets\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\n', '', text)  # Remove newlines\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Remove words containing numbers\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply text preprocessing\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# Show sample processed text\n",
    "print(df[[\"text\", \"cleaned_text\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff1b804-e46c-4275-9201-01af5b14ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for efficiency\n",
    "X = vectorizer.fit_transform(df[\"cleaned_text\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Split data into training & testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8556589-e0d4-4454-af91-b4ac8116fd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Naïve Bayes Model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8584ffc6-74b6-477e-be88-30594c3f8e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96        89\n",
      "           1       0.95      0.99      0.97       111\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.97      0.96      0.96       200\n",
      "weighted avg       0.97      0.96      0.96       200\n",
      "\n",
      "Random Forest Accuracy: 0.995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        89\n",
      "           1       1.00      0.99      1.00       111\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       0.99      1.00      0.99       200\n",
      "weighted avg       1.00      0.99      1.00       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict using Naïve Bayes\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Predict using Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bdf7922-5f24-4ee0-b012-94d9ea0662e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71d49b4e-d363-430d-915e-e98b7feee5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "with open(\"model.pkl\", \"rb\") as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"rb\") as vectorizer_file:\n",
    "    vectorizer = pickle.load(vectorizer_file)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if not text.strip():  # Handle empty input\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)  # Remove special characters & numbers\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stopwords.words(\"english\")]  # Remove stopwords\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "    tokens = [stemmer.stem(word) for word in tokens]  # Stemming\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def home():\n",
    "    prediction = None\n",
    "    result = None\n",
    "\n",
    "    if request.method == \"POST\":\n",
    "        news_text = request.form.get(\"news\", \"\").strip()  # Get input & handle empty string\n",
    "        \n",
    "        if news_text:\n",
    "            processed_text = preprocess_text(news_text)\n",
    "            text_vector = vectorizer.transform([processed_text])  # Convert text to vector\n",
    "            prediction = model.predict(text_vector)[0]  # Predict (0 = Fake, 1 = Real)\n",
    "            result = \"Real News ✅\" if prediction == 1 else \"Fake News ❌\"\n",
    "        else:\n",
    "            result = \"Please enter a news article!\"\n",
    "\n",
    "    return render_template(\"index.html\", result=result, news_text=news_text if request.method == \"POST\" else \"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56068b85-0f1d-4aab-a321-04f22517f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save models & vectorizer\n",
    "pickle.dump(vectorizer, open(\"vectorizer.pkl\", \"wb\"))\n",
    "pickle.dump(nb_model, open(\"fake_news_model.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca6594f6-7920-4c52-915e-51dc84c4e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting templates/index.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile templates/index.html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Fake News Detector</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            text-align: center;\n",
    "            margin: 50px;\n",
    "        }\n",
    "        textarea {\n",
    "            width: 60%;\n",
    "            height: 100px;\n",
    "        }\n",
    "        input {\n",
    "            padding: 10px 20px;\n",
    "            font-size: 16px;\n",
    "            margin-top: 10px;\n",
    "            cursor: pointer;\n",
    "        }\n",
    "        .result {\n",
    "            margin-top: 20px;\n",
    "            font-size: 20px;\n",
    "            font-weight: bold;\n",
    "            color: blue;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Fake News Detection System</h1>\n",
    "    <form method=\"post\">\n",
    "        <textarea name=\"news\" placeholder=\"Enter news article text here...\">{{ news_text }}</textarea>\n",
    "        <br>\n",
    "        <input type=\"submit\" value=\"Check News\">\n",
    "    </form>\n",
    "    \n",
    "    {% if result is not none %}\n",
    "    <div class=\"result\">Prediction: {{ result }}</div>\n",
    "    {% endif %}\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ee821b3-1fa3-47d3-a2da-22ccd137cbdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded successfully!\n",
      "📌 Sample text before processing: ['WASHINGTON (Reuters) - Nikki Haley, the U.S. ambassador to the United Nations, said on Sunday that any woman who has felt violated or mistreated by a man has every right to speak up, even if she is accusing President Donald Trump. “Women who accuse anyone should be heard,” Haley said on CBS’s “Face the Nation.” “They should be heard, and they should be dealt with.” Washington has been roiled by sexual misconduct scandals, with accusations leading to the resignations last week of three members of Congress. The growing wave of women reporting abuse or misconduct has brought down powerful men, from movie producer Harvey Weinstein to popular television personality Matt Lauer. Haley, discussing that cultural shift, applauded the women who have come forward: “I’m proud of their strength. I’m proud of their courage.” Asked how people should assess the accusers of the president, Haley said, it was “the same thing.” More than 10 women have accused Trump of sexual misconduct before he was president. While filming a segment of the television program “Access Hollywood,” he talked about kissing and groping women. Trump has denied the misconduct allegations, although he apologized for his comments, which he called “locker room” talk. White House spokeswoman Sarah Sanders said on Thursday that sexual harassment allegations against Trump were addressed by the American people when they voted him into office in November 2016. Asked whether Trump’s election settled the matter, Haley said: “That’s for the people to decide. I know that he was elected, but women should always feel comfortable coming forward, and we should all be willing to listen to them.” On Tuesday, voters in the heavily Republican state of Alabama will cast their ballots in a race involving Republican Roy Moore, a former state judge, and Democrat Doug Jones, a former U.S. attorney. Moore has been accused of sexual misconduct toward women when they were teenagers and he was in his 30s. One woman said he tried to initiate sexual contact with her when she was 14. Reuters has not independently verified the accusations, which Moore, a conservative Christian, has denied. Many Republicans, including Alabama’s senior U.S. senator, Richard Shelby, have distanced themselves from Moore. But Trump has endorsed him, saying he wants to see the Senate seat stay in Republicans’ hands. ', 'WASHINGTON (Reuters) - A federal appeals court in Washington on Friday rejected a bid by President Donald Trump’s administration to prevent the U.S. military from accepting transgender recruits starting Jan. 1, the second court to issue such a ruling this week. Four federal judges around the country have issued injunctions blocking Trump’s ban on transgender people from the military, including one that was also handed down on Friday. The administration has appealed the previous three rulings. In a six-page order, the three-judge-panel of the U.S. Court of Appeals for the District of Columbia Circuit said the administration had “not shown a strong likelihood that they will succeed on the merits of their challenge” to a district court’s order blocking the ban. On Thursday the Richmond, Virginia-based 4th U.S. Circuit Court of Appeals said it was denying the administration’s request while the appeal proceeds. The two courts’ actions could prompt the administration to ask the conservative-majority U.S. Supreme Court to intervene. Also on Friday, a federal trial court in Riverside, California, blocked the ban while the case proceeds, making it the fourth to do so, after similar rulings in Baltimore, Seattle and Washington, D.C. U.S. District Judge Jesus Bernal said without the injunction the plaintiffs, including current and aspiring service members, would suffer irreparable harm. “There is nothing any court can do to remedy a government-sent message that some citizens are not worthy of the military uniform simply because of their gender,” he added. The administration had argued that the Jan. 1 deadline for accepting transgender recruits was problematic because tens of thousands of personnel would have to be trained on the medical standards needed to process transgender applicants, and the military was not ready for that. The Obama administration had set a deadline of July 1, 2017, to begin accepting transgender recruits, but Trump’s defense secretary, James Mattis, postponed that date to Jan. 1. In an August memorandum, Trump gave the military until March 2018 to revert to a policy prohibiting openly transgender individuals from joining the military and authorizing their discharge. The memo also halted the use of government funds for sex-reassignment surgery for active-duty personnel. ', 'Add Trump s national security adviser, General H.R. McMaster, to the growing list of high-profile people who think he s a total buffoon. McMaster, a seasoned combat officer in the Army, is reportedly fed up with Trump s lack of intelligence, lack of focus, and inability to understand even the most basic premises of national security.According to several Buzzfeed sources, McMaster was attending a private dinner with Oracle CEO Safra Catz, and dragged Trump through the mud, calling him an  idiot,  a  dope,  and someone with the intelligence of  a kindergartner.  Another source who wasn t at the dinner told Buzzfeed that McMaster has made similar comments before.Recently, Secretary of State Rex Tillerson reportedly called Trump a moron, prompting the man-baby to jump on Twitter and challenge Tillerson to an IQ test. Trump either knows exactly what he is and is riddled with self-loathing and embarrassment over it, or he honestly believes he has one of the great minds and memories of all time, just like he s claimed, and his fragile fee-fees can t handle anyone thinking otherwise.Then there s Senator Bob Corker, who s had no qualms at all about criticizing Trump, which led the two of them into a Twitter war because Trump can t stand looking like the pathetic, ineffective pseudo-man that he is. And we all know how Senator Jeff Flake feels.Officials who are on Trump s side, however, push back against all these things vehemently. From their stories, everything is hunky-dory in the White House, and Trump is highly competent, calm, collected, respected   in short, presidential. Anyone inside or outside the White House talking badly about him is just, well, jealous ? Or un-American ? To them, these stories are nothing more than people deliberately working to undermine Trump, at least in the world Trump and his loyalists are desperate to create.These stories keep coming out, though, and when taken with his embarrassing public appearances and his ridiculous behavior on Twitter, they are ever harder to ignore. Buzzfeed has five sources for McMaster s words, with a sixth saying they d heard similar words from him before.This dinner between McMaster and Catz took place over the summer, and was allegedly peppered with insults toward Trump and other senior members of the White House staff, including Trump s son-in-law, Jared Kushner. McMaster reportedly (and, if true, correctly) said that Kushner doesn t belong in the White House and shouldn t be involved in national security matters.In short, Trump doesn t have the respect he thinks he has. Poor widdle Donnie.Featured image via Thomas Peter-Pool/Getty Images']\n",
      "🚀 Starting preprocessing...\n",
      "✅ Preprocessing complete!\n",
      "🔹 Splitting dataset...\n",
      "🔹 Vectorizing text...\n",
      "🔹 Training the model...\n",
      "✅ Model training complete!\n",
      "🔹 Evaluating the model...\n",
      "🎯 Model Accuracy: 0.94\n",
      "✅ Model and Vectorizer Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# ✅ Load the datasets (Fixed variable names)\n",
    "fake_df = pd.read_csv(\"Fake.csv\", nrows=500)  \n",
    "true_df = pd.read_csv(\"True.csv\", nrows=500)  \n",
    "\n",
    "print(\"✅ Dataset loaded successfully!\")\n",
    "\n",
    "# ✅ Add labels\n",
    "fake_df[\"label\"] = 0  # Fake news\n",
    "true_df[\"label\"] = 1  # True news\n",
    "\n",
    "# ✅ Combine datasets\n",
    "df = pd.concat([fake_df, true_df], axis=0)\n",
    "df = df.sample(frac=1).reset_index(drop=True)  # Shuffle dataset\n",
    "\n",
    "# ✅ Check if 'text' column exists\n",
    "if \"text\" not in df.columns:\n",
    "    raise ValueError(\"❌ Column 'text' not found in dataset!\")\n",
    "\n",
    "# ✅ Print sample text before preprocessing\n",
    "print(\"📌 Sample text before processing:\", df[\"text\"].head(3).tolist())\n",
    "\n",
    "# 🔹 Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)  # Remove special characters & numbers\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stopwords.words(\"english\")]  # Remove stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# ✅ Debugging: Print status\n",
    "print(\"🚀 Starting preprocessing...\")  \n",
    "\n",
    "# ✅ Apply preprocessing (Fixed multiprocessing issue)\n",
    "df[\"processed_text\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "print(\"✅ Preprocessing complete!\")\n",
    "\n",
    "# ✅ Splitting dataset\n",
    "print(\"🔹 Splitting dataset...\")  \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"processed_text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Convert text into TF-IDF vectors\n",
    "print(\"🔹 Vectorizing text...\")  \n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# ✅ Train the Naïve Bayes model\n",
    "print(\"🔹 Training the model...\")  \n",
    "trained_model = MultinomialNB()\n",
    "trained_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"✅ Model training complete!\")  \n",
    "\n",
    "# ✅ Evaluate the model\n",
    "print(\"🔹 Evaluating the model...\")  \n",
    "y_pred = trained_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"🎯 Model Accuracy: {accuracy:.2f}\")  # Should print accuracy ~90%\n",
    "\n",
    "# 🔹 Save the trained model and vectorizer\n",
    "with open(\"model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(trained_model, file)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "print(\"✅ Model and Vectorizer Saved Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa701b51-882e-4691-bb51-bb2a787b9011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mehar'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Ensure it's inside print()\n",
    "os.getcwd()  # Display the path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e27012e9-dda0-4330-a1ec-f5d5c3fa58f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Ensure 'trained_model' and 'vectorizer' are properly trained\n",
    "with open(\"model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(trained_model, file)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df50e703-5f33-41cd-9c39-a58a92990891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: <class 'sklearn.naive_bayes.MultinomialNB'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the trained model\n",
    "with open(\"model.pkl\", \"rb\") as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "# Check the model type\n",
    "print(\"Model type:\", type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "282ea317-6953-4780-9e93-2949f1a26a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run On Command Prompt BY python app.py on Command prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
