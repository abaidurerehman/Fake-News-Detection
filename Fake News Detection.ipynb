{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30dbb1ea-b37c-4772-80ba-a4cd0d7a2143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\new folder\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9ceee7-8b81-4f01-a7fa-41db5f1e506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765d671c-696b-42f1-8148-f27fd6aecc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\New folder\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d5cfed7-d6cb-414a-ac39-02cc6d68b881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\new folder\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca2d0b5-5f6a-4120-8969-35afd599d3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported successfully!\n",
      "Scikit-Learn Version: 1.6.1\n",
      "NLTK Version: 3.8.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "import flask\n",
    "\n",
    "print(\"All packages imported successfully!\")\n",
    "print(\"Scikit-Learn Version:\", sklearn.__version__)\n",
    "print(\"NLTK Version:\", nltk.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566fbdb8-6838-4102-a407-56a7a8cb8624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\new folder\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in e:\\new folder\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in e:\\new folder\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in e:\\new folder\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: flask in e:\\new folder\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\new folder\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\new folder\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\new folder\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in e:\\new folder\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\new folder\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in e:\\new folder\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in e:\\new folder\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in e:\\new folder\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in e:\\new folder\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in e:\\new folder\\lib\\site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\new folder\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\new folder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn nltk flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac61b481-bcfa-4d6f-bbec-e477781fc230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\new folder\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in e:\\new folder\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in e:\\new folder\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in e:\\new folder\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: flask in e:\\new folder\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\new folder\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\new folder\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\new folder\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\new folder\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in e:\\new folder\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\new folder\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in e:\\new folder\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in e:\\new folder\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in e:\\new folder\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in e:\\new folder\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in e:\\new folder\\lib\\site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: colorama in e:\\new folder\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\new folder\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\new folder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn nltk flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "850c7ec4-0d0c-452e-9415-b21d1de052b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8949d6c4-c4a3-4691-bb30-c02ec8789602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset prepared successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load only 10,000 rows to reduce processing time\n",
    "fake_data = pd.read_csv(\"Fake.csv\", nrows=500)\n",
    "true_data = pd.read_csv(\"True.csv\", nrows=500)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "\n",
    "# Add labels: 1 for True, 0 for Fake\n",
    "fake_data[\"label\"] = 0\n",
    "true_data[\"label\"] = 1\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([fake_data, true_data])\n",
    "\n",
    "# Shuffle the dataset to mix fake and real news\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset prepared successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdcf9dda-9a2e-4f75-80f2-3833c4a30297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  WASHINGTON (Reuters) - The Trump administratio...   \n",
      "1  WASHINGTON (Reuters) - A U.S. District Court j...   \n",
      "2  TRIPOLI (Reuters) - Libya’s internationally re...   \n",
      "3  WASHINGTON (Reuters) - People would be able to...   \n",
      "4  WASHINGTON (Reuters) - The White House expects...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  washington reuters trump administration wednes...  \n",
      "1  washington reuters u district court judge frid...  \n",
      "2  tripoli reuters libya ’ internationally recogn...  \n",
      "3  washington reuters people would able bring leg...  \n",
      "4  washington reuters white house expects u congr...  \n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text in brackets\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\n', '', text)  # Remove newlines\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Remove words containing numbers\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply text preprocessing\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# Show sample processed text\n",
    "print(df[[\"text\", \"cleaned_text\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff1b804-e46c-4275-9201-01af5b14ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for efficiency\n",
    "X = vectorizer.fit_transform(df[\"cleaned_text\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Split data into training & testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8556589-e0d4-4454-af91-b4ac8116fd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Naïve Bayes Model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8584ffc6-74b6-477e-be88-30594c3f8e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       101\n",
      "           1       0.95      0.97      0.96        99\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.96      0.96      0.96       200\n",
      "weighted avg       0.96      0.96      0.96       200\n",
      "\n",
      "Random Forest Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       101\n",
      "           1       1.00      1.00      1.00        99\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict using Naïve Bayes\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Predict using Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bdf7922-5f24-4ee0-b012-94d9ea0662e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71d49b4e-d363-430d-915e-e98b7feee5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "with open(\"model.pkl\", \"rb\") as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"rb\") as vectorizer_file:\n",
    "    vectorizer = pickle.load(vectorizer_file)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if not text.strip():  # Handle empty input\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)  # Remove special characters & numbers\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stopwords.words(\"english\")]  # Remove stopwords\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "    tokens = [stemmer.stem(word) for word in tokens]  # Stemming\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def home():\n",
    "    prediction = None\n",
    "    result = None\n",
    "\n",
    "    if request.method == \"POST\":\n",
    "        news_text = request.form.get(\"news\", \"\").strip()  # Get input & handle empty string\n",
    "        \n",
    "        if news_text:\n",
    "            processed_text = preprocess_text(news_text)\n",
    "            text_vector = vectorizer.transform([processed_text])  # Convert text to vector\n",
    "            prediction = model.predict(text_vector)[0]  # Predict (0 = Fake, 1 = Real)\n",
    "            result = \"Real News ✅\" if prediction == 1 else \"Fake News ❌\"\n",
    "        else:\n",
    "            result = \"Please enter a news article!\"\n",
    "\n",
    "    return render_template(\"index.html\", result=result, news_text=news_text if request.method == \"POST\" else \"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56068b85-0f1d-4aab-a321-04f22517f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save models & vectorizer\n",
    "pickle.dump(vectorizer, open(\"vectorizer.pkl\", \"wb\"))\n",
    "pickle.dump(nb_model, open(\"fake_news_model.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f259c60-a6b4-41d4-890c-a8c05c4ff8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"templates\", exist_ok=True)  # Creates 'templates' folder if it doesn't exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca6594f6-7920-4c52-915e-51dc84c4e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing templates/index.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile templates/index.html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Fake News Detector</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            text-align: center;\n",
    "            margin: 50px;\n",
    "        }\n",
    "        textarea {\n",
    "            width: 60%;\n",
    "            height: 100px;\n",
    "        }\n",
    "        input {\n",
    "            padding: 10px 20px;\n",
    "            font-size: 16px;\n",
    "            margin-top: 10px;\n",
    "            cursor: pointer;\n",
    "        }\n",
    "        .result {\n",
    "            margin-top: 20px;\n",
    "            font-size: 20px;\n",
    "            font-weight: bold;\n",
    "            color: blue;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Fake News Detection System</h1>\n",
    "    <form method=\"post\">\n",
    "        <textarea name=\"news\" placeholder=\"Enter news article text here...\">{{ news_text }}</textarea>\n",
    "        <br>\n",
    "        <input type=\"submit\" value=\"Check News\">\n",
    "    </form>\n",
    "    \n",
    "    {% if result is not none %}\n",
    "    <div class=\"result\">Prediction: {{ result }}</div>\n",
    "    {% endif %}\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ee821b3-1fa3-47d3-a2da-22ccd137cbdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mehar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded successfully!\n",
      "📌 Sample text before processing: ['WASHINGTON (Reuters) - The No. 2 Republican in the U.S. House of Representatives said on Wednesday the Senate would likely vote on its tax bill this week and that lawmakers from both chambers would get together “as quickly as possible” to resolve differences between their two bills. “I know the Senate is continuing to work hard to pass tax reform,” House Majority Leader Kevin McCarthy told reporters. “We want to make sure we move to go to conference as quickly as possible.” ', 'Well, here s a Twitter post that backfired on Donald Trump.Over the weekend, billionaire Prince Alwaleed bin Talal, who owns a stake in Fox News, along with several other princes and former cabinet officials, were arrested for corruption by order of Crown Prince Mohammad bin Salman.Ironically, Trump tweeted out his support of the sweeping arrests on Monday.I have great confidence in King Salman and the Crown Prince of Saudi Arabia, they know exactly what they are doing .  Donald J. Trump (@realDonaldTrump) November 6, 2017 .Some of those they are harshly treating have been  milking  their country for years!  Donald J. Trump (@realDonaldTrump) November 6, 2017Let that sink in for a minute. Donald Trump, the man who has literally spent every moment of his adult life milking his own country and continues to do so now from the Oval Office, agrees that people who do what he does should be treated harshly.Trump and his administration are currently under investigation for colluding with a foreign state to undermine our democratic process. Trump is also a tax evader and has made deals with some very shady people including people with mob and terrorist connections.In fact, Trump s own tax plan would especially benefit him and his family. And he has placed his own family members in high White House positions, all while using the executive branch to promote his businesses, all of which violates ethics rules.Some Twitter users pointed out the irony and hypocrisy of Trump s tweet.Like your team is doing??? pic.twitter.com/51L89Rrnfs  sweetsallysue (@sweetsallysue) November 7, 2017RELEASE YOUR TAXES and we\\'ll see who has been \"milking\" their country for years! #PutinsPuppet #FakePresident  RandeMande (@almondleafer) November 7, 2017Like you have been milking US for years? #Traitor  Reap what you sow (@2017moderate) November 7, 2017That is a hilarious statement coming from you, that\\'s exactly what you are doing to us.  jbarton (@jlbarton618) November 6, 2017Make no mistake, Trump has milked the United States more than anyone and he intends to milk much more out of taxpayers unless he is removed from office and put in prison where he belongs.Featured Image: Drew Angerer/Getty Images', 'WASHINGTON (Reuters) - U.S. President Donald Trump called on the Republican Congress to pass a short-term government spending bill later on Thursday to avoid a shutdown when current funding expires at midnight on Friday. Republicans in the House of Representatives have unveiled a stopgap spending bill that would allow the government to stay open at current funding levels. “Pass the C.R. (continuing resolution) TODAY and keep our Government OPEN!” Trump wrote in a post on Twitter.  ']\n",
      "🚀 Starting preprocessing...\n",
      "✅ Preprocessing complete!\n",
      "🔹 Splitting dataset...\n",
      "🔹 Vectorizing text...\n",
      "🔹 Training the model...\n",
      "✅ Model training complete!\n",
      "🔹 Evaluating the model...\n",
      "🎯 Model Accuracy: 0.97\n",
      "✅ Model and Vectorizer Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# ✅ Load the datasets (Fixed variable names)\n",
    "fake_df = pd.read_csv(\"Fake.csv\", nrows=500)  \n",
    "true_df = pd.read_csv(\"True.csv\", nrows=500)  \n",
    "\n",
    "print(\"✅ Dataset loaded successfully!\")\n",
    "\n",
    "# ✅ Add labels\n",
    "fake_df[\"label\"] = 0  # Fake news\n",
    "true_df[\"label\"] = 1  # True news\n",
    "\n",
    "# ✅ Combine datasets\n",
    "df = pd.concat([fake_df, true_df], axis=0)\n",
    "df = df.sample(frac=1).reset_index(drop=True)  # Shuffle dataset\n",
    "\n",
    "# ✅ Check if 'text' column exists\n",
    "if \"text\" not in df.columns:\n",
    "    raise ValueError(\"❌ Column 'text' not found in dataset!\")\n",
    "\n",
    "# ✅ Print sample text before preprocessing\n",
    "print(\"📌 Sample text before processing:\", df[\"text\"].head(3).tolist())\n",
    "\n",
    "# 🔹 Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)  # Remove special characters & numbers\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stopwords.words(\"english\")]  # Remove stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# ✅ Debugging: Print status\n",
    "print(\"🚀 Starting preprocessing...\")  \n",
    "\n",
    "# ✅ Apply preprocessing (Fixed multiprocessing issue)\n",
    "df[\"processed_text\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "print(\"✅ Preprocessing complete!\")\n",
    "\n",
    "# ✅ Splitting dataset\n",
    "print(\"🔹 Splitting dataset...\")  \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"processed_text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Convert text into TF-IDF vectors\n",
    "print(\"🔹 Vectorizing text...\")  \n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# ✅ Train the Naïve Bayes model\n",
    "print(\"🔹 Training the model...\")  \n",
    "trained_model = MultinomialNB()\n",
    "trained_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"✅ Model training complete!\")  \n",
    "\n",
    "# ✅ Evaluate the model\n",
    "print(\"🔹 Evaluating the model...\")  \n",
    "y_pred = trained_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"🎯 Model Accuracy: {accuracy:.2f}\")  # Should print accuracy ~90%\n",
    "\n",
    "# 🔹 Save the trained model and vectorizer\n",
    "with open(\"model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(trained_model, file)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "print(\"✅ Model and Vectorizer Saved Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa701b51-882e-4691-bb51-bb2a787b9011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehar\\Fake News Detection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mehar\\\\Fake News Detection'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Ensure it's inside print()\n",
    "os.getcwd()  # Display the path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e27012e9-dda0-4330-a1ec-f5d5c3fa58f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Ensure 'trained_model' and 'vectorizer' are properly trained\n",
    "with open(\"model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(trained_model, file)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df50e703-5f33-41cd-9c39-a58a92990891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: <class 'sklearn.naive_bayes.MultinomialNB'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the trained model\n",
    "with open(\"model.pkl\", \"rb\") as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "# Check the model type\n",
    "print(\"Model type:\", type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "282ea317-6953-4780-9e93-2949f1a26a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run On Command Prompt BY python app.py on Command prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
